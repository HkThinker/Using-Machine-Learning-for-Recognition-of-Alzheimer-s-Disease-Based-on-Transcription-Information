{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_ad_dir = '../train/transcription/cd/*'\n",
    "controls_dir = '../train/transcription/cc/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(file_name):\n",
    "    par = {}\n",
    "    par['id'] = file_name.split('/')[-1].split('.cha')[0]\n",
    "    f = iter(open(file_name))\n",
    "    l = next(f)\n",
    "    speech = []\n",
    "    try:\n",
    "        curr_speech = ''\n",
    "        while (True):\n",
    "            if l.startswith('*PAR:') or l.startswith('*INV'):\n",
    "                curr_speech = l\n",
    "            elif len(curr_speech) != 0 and not(l.startswith('%') or l.startswith('*')):\n",
    "                curr_speech += l\n",
    "            elif len(curr_speech) > 0:\n",
    "                speech.append(curr_speech)\n",
    "                curr_speech = ''\n",
    "            l = next(f)\n",
    "    except StopIteration:\n",
    "        pass\n",
    "\n",
    "    clean_par_speech = []\n",
    "    clean_all_speech = []\n",
    "    is_par = False\n",
    "    for s in speech:\n",
    "        \n",
    "        def _clean(s):\n",
    "            s = re.sub('\\x15\\d*_\\d*\\x15', '', s) # remove time block \n",
    "            s = re.sub('\\[.*\\]', '', s) # remove other speech artifacts [.*]\n",
    "            s = s.strip()\n",
    "            s = re.sub('\\t|\\n|<|>', '', s) # remove tab, new lines,ampersand\n",
    "            return s\n",
    "        \n",
    "        if s.startswith('*PAR:'):\n",
    "            is_par = True\n",
    "        elif s.startswith('*INV:'):\n",
    "            is_par = False\n",
    "            s = re.sub('\\*INV:\\t', '', s) # remove prefix\n",
    "        if is_par:\n",
    "            s = re.sub('\\*PAR:\\t', '', s) # remove prefix    \n",
    "            clean_par_speech.append(_clean(s))\n",
    "        clean_all_speech.append(_clean(s))\n",
    "        \n",
    "    par['speech'] = speech\n",
    "    par['clean_speech'] = clean_all_speech\n",
    "    par['clean_par_speech'] = clean_par_speech\n",
    "    par['joined_all_speech'] = ' '.join(clean_all_speech)\n",
    "    par['joined_all_par_speech'] = ' '.join(clean_par_speech)\n",
    "    \n",
    "    return par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_train_data():\n",
    "    return _parse_data('../data/train')\n",
    "\n",
    "def _parse_data(data_dir):\n",
    "    prob_ad_dir = f'{data_dir}/transcription/cd/*'\n",
    "    controls_dir = f'{data_dir}/transcription/cc/*'\n",
    "    \n",
    "    prob_ad = [extract_data(fn) for fn in glob(prob_ad_dir)]\n",
    "    controls = [extract_data(fn) for fn in glob(controls_dir)]\n",
    "    controls_df = pd.DataFrame(controls)\n",
    "    prob_ad_df = pd.DataFrame(prob_ad)\n",
    "    controls_df['ad'] = 0\n",
    "    prob_ad_df['ad'] = 1\n",
    "    df = pd.concat([controls_df, prob_ad_df]).sample(frac=1).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = parse_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomforst_models(text: pd.Series, labels: list, shuffle=True):\n",
    "    ## AD Classification Pred\n",
    "    \n",
    "    # sklearn pipeline\n",
    "    param_space = {\n",
    "        'vec__max_features': [100, 500, 1000, 2000, 10000],\n",
    "        'vec__stop_words': ['english', None],\n",
    "        'vec__analyzer': ['word', 'char'],\n",
    "        'vec__max_df': [0.5, 0.75, 1.0],\n",
    "        'vec__sublinear_tf': [True, False]    \n",
    "     \n",
    "    }    \n",
    "    param_space['clf__n_estimators'] = [10]\n",
    "    param_space['clf__max_depth'] = [5, 10, 15]\n",
    "    param_space['clf__min_samples_split']= [2, 5]\n",
    "    param_space['clf__min_samples_leaf']= [1, 2, 4]\n",
    "    param_space ['clf__bootstrap']= [True, False]\n",
    "\n",
    "    clf_pipe = Pipeline([\n",
    "        ('vec', TfidfVectorizer()),\n",
    "        ('clf', RandomForestClassifier())\n",
    "    ])\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(text, labels, random_state=random_state, test_size=0.2,shuffle=shuffle)\n",
    "    search = GridSearchCV(clf_pipe, param_space, cv=10, n_jobs=6)\n",
    "    search.fit(train_features, train_labels)\n",
    "    clf_pipe.set_params(**search.best_params_)\n",
    "    print(search.best_params_)\n",
    "    clf_pipe.fit(train_features, train_labels)\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer.fit(train_features)\n",
    "    vocabulary_size = len(vectorizer.vocabulary_)\n",
    "    print(vocabulary_size)\n",
    "    return clf_pipe, test_features,test_labels,train_features,train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ran_par,test_features,test_labels,train_features,train_labels = randomforst_models(train_df.joined_all_par_speech, train_df.ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# # confusion matrix for AD classification\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plot_confusion_matrix(clf_ran_par, train_features, train_labels, ax=ax)\n",
    "ax.set_title('Confusion Matrix for AD Classification based on the train dataset')\n",
    "plt.savefig('train_cm.png')\n",
    "# confusion matrix for AD classification\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plot_confusion_matrix(clf_ran_par, test_features, test_labels, ax=ax)\n",
    "ax.set_title('Confusion Matrix for AD Classification based on the test dataset')\n",
    "plt.savefig('test_cm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 在获得混淆矩阵结果后,重新绘制混淆矩阵,便于观看\n",
    "confusion_matrix = np.array([[41, 2],\n",
    "                             [0,43]])\n",
    "\n",
    "# 定义类别标签\n",
    "labels = ['non-AD', 'AD']\n",
    "\n",
    "# 绘制混淆矩阵\n",
    "plt.imshow(confusion_matrix, cmap='Blues')\n",
    "\n",
    "# 设置标题和颜色条\n",
    "plt.title('Confusion Matrix for train dataset', fontsize=18)\n",
    "plt.colorbar()\n",
    "\n",
    "# 添加类别标签\n",
    "tick_marks = np.arange(len(labels))\n",
    "plt.xticks(tick_marks, labels, fontsize=18)\n",
    "plt.yticks(tick_marks, labels, fontsize=18)\n",
    "\n",
    "# 添加数值标签\n",
    "for i in range(len(labels)):\n",
    "    for j in range(len(labels)):\n",
    "        plt.text(j, i, confusion_matrix[i, j],\n",
    "                 ha='center', va='center', color='black', weight='bold', fontsize=20)\n",
    "\n",
    "# 显示图形\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
